{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This classification model is based on MultiNomialNB \n",
    "# Pay attention to cleanning procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "import csv\n",
    "import string\n",
    "import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the categorized data to classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_key_exists(input_key,input_collection):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    checks if key exists on the collection\n",
    "    \n",
    "    :param input_key - the key to search on the collection\n",
    "    :param input_collection - the collection\n",
    "    \n",
    "    :returns True if key exists, else False\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    key_found = False\n",
    "    for key in input_collection.keys():\n",
    "        if key == input_key:\n",
    "            key_found = True\n",
    "            break\n",
    "    \n",
    "    return key_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sub_categories_count(input_category:str, input_path:str):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    checks how many subcategories exists to an input category.\n",
    "    \n",
    "    :param input_category - a string describes the category\n",
    "    :param input_path - the verdicts files path\n",
    "    \n",
    "    :returns a dictionary which has the category names as keys and the occurences count as values\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    #initialization\n",
    "    category_dict = dict()\n",
    "    \n",
    "    # iterate on the files on the input path\n",
    "    for scanned_file in os.scandir(input_path):\n",
    "        \n",
    "        # look for directories only due to the fact that all the extracted verdicts\n",
    "        # are already have been set to the right directory tree\n",
    "        \n",
    "        if scanned_file.is_dir() == True:\n",
    "            \n",
    "            # split the directory name by ' - ' - that is how the justice department \n",
    "            # have been decided to seperate the category and the sub category\n",
    "            \n",
    "            dir_name = os.path.basename(scanned_file)\n",
    "            splitted_category = str(dir_name).split(\" - \")\n",
    "            \n",
    "            # check the len of the splitted catregory\n",
    "            # there are two main representations, one sub or two sub\n",
    "            if splitted_category[0] == input_category:\n",
    "                if len(splitted_category) == 3:\n",
    "                    for first_sub in os.scandir(scanned_file):\n",
    "                       \n",
    "                        if check_if_key_exists(splitted_category[1]+ \" - \" + splitted_category[2],category_dict):\n",
    "                            category_dict[splitted_category[1]+ \" - \" + splitted_category[2]] += 1\n",
    "                        else:\n",
    "                            category_dict[splitted_category[1]+ \" - \" + splitted_category[2]] = 1\n",
    "                else:\n",
    "                    for first_sub in os.scandir(scanned_file):\n",
    "                        \n",
    "                        if check_if_key_exists(splitted_category[1],category_dict):\n",
    "                            category_dict[splitted_category[1]] += 1\n",
    "                        else:\n",
    "                            category_dict[splitted_category[1]] = 1\n",
    "            \n",
    "    category_dict[input_category + \" Total\"] = sum(category_dict.values())\n",
    "    \n",
    "    return category_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_categories_count(input_path:str):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    counts the quantity of main categories\n",
    "    \n",
    "    :param input_path - a string holds the path to the root folder\n",
    "    \n",
    "    :returns a dictionary with the names of the \n",
    "     categories and the verdicts present for each and every of them\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # initalization\n",
    "    category_dict = dict()\n",
    "    \n",
    "    # iterate on the folder\n",
    "    for scanned_file in os.scandir(input_path):\n",
    "        \n",
    "        # look for directories only\n",
    "        if scanned_file.is_dir() == True:\n",
    "            \n",
    "            # look for the main category only, for example: 'Civil'\n",
    "            dir_name = os.path.basename(scanned_file)\n",
    "            splitted_category = str(dir_name).split(\" - \")\n",
    "            cur_category = splitted_category[0]\n",
    "            \n",
    "            # advance counter according to the findings\n",
    "            for sub_cat in os.scandir(scanned_file):\n",
    "                if check_if_key_exists(cur_category,category_dict):\n",
    "                    category_dict[cur_category] += 1\n",
    "                else:\n",
    "                    category_dict[cur_category] = 1\n",
    "    \n",
    "    return category_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dest_path = 'C:/Users/Itai Ofir/HebrewCourtVerdictsAnalyzer/ML/data/readytoclassify'\n",
    "# test_category = 'Civil'\n",
    "# result_sub_cat_dict = get_sub_categories_count(test_category,dest_path)\n",
    "# result_cat_dict = get_categories_count(dest_path)\n",
    "# print_dict(result_sub_cat_dict)\n",
    "# print(\" - - - - - - - - - - - - \")\n",
    "# print_dict(result_cat_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_dict(input_dict):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    prints given dictionary\n",
    "    \n",
    "    :param input_dict - dictionary\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    for key in input_dict:\n",
    "        print(key + \" : \" + str(input_dict[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_category = 'Administrative'\n",
    "# dest_path = 'C:/Users/Itai Ofir/HebrewCourtVerdictsAnalyzer/ML/data/readytoclassify'\n",
    "# calculate_required_categories_count_ratio(test_category,dest_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create train and test based on previous dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_train_and_test_frames(input_category,input_category_count_dictionary,verdicts_path):\n",
    "#     appereances_ratio_dict = input_category_count_dictionary.copy()\n",
    "#     total_tagged_verdicts = int(sum(input_category_count_dictionary.values()))\n",
    "#     for key,val in zip(input_category_count_dictionary.keys(),input_category_count_dictionary.values()):\n",
    "#         appereances_ratio_dict[key] = val/total_tagged_verdicts\n",
    "#     print_dict(appereances_ratio_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bankruptcy : 1028\n",
      "Contracts : 1085\n",
      "Corporate : 1\n",
      "Equity and Trusts : 246\n",
      "Fiscal : 1\n",
      "Intellectual Property : 105\n",
      "Land : 1605\n",
      "other : 1628\n",
      "Procedure and Evidence : 758\n",
      "Property : 946\n",
      "Torts : 644\n",
      "Civil Total : 8047\n",
      " - - - - - - - - - - - - - - - - - - - - - \n",
      "Administrative : 9959\n",
      "Civil : 8047\n",
      "Constitutional : 1932\n",
      "Criminal : 4410\n",
      "Family : 148\n",
      "International law : 120\n",
      "Labor and Employment : 532\n",
      "National security, military, and the territories : 2943\n",
      "Religious : 224\n",
      "Social security, Health Insurance, Pension : 310\n",
      " - - - - - - - - - - - - - - - - - - - - - \n"
     ]
    }
   ],
   "source": [
    "dest_path = 'C:/Users/Itai/HebrewCourtVerdictsAnalyzer/ML/data/readytoclassify'\n",
    "test_category = 'Civil'\n",
    "result_sub_cat_dict = get_sub_categories_count(test_category,dest_path)\n",
    "result_cat_dict = get_categories_count(dest_path)\n",
    "print_dict(result_sub_cat_dict)\n",
    "print(\" - - - - - - - - - - - - - - - - - - - - - \")\n",
    "print_dict(result_cat_dict)\n",
    "print(\" - - - - - - - - - - - - - - - - - - - - - \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creating train,test df of specified category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_test_of_specified_verdict_category(input_category:str,input_path:str, desired_test_size):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    based on the root directory tree, this method will make a data frame for \n",
    "    every category which has the exact amount of matched verdicts vs non matched.\n",
    "    for instance - 1000 'Civil' verdicts vs 1000 mixture of 'Administrative'\n",
    "    , 'Constitutional' and so on.\n",
    "    \n",
    "    :param input_category - a string that holds the category name - \n",
    "     Attention! this name must be identical to the name present on the root directory\n",
    "     \n",
    "    :param input_path - a string that holds the root directory path\n",
    "    \n",
    "    :param desired_test_size - a number between 0-1 that corresponds to the \n",
    "     precentage of test data that will be created and returned.\n",
    "     needless to say that will fix the train precentage as well.\n",
    "    \n",
    "    :returns a data frame for the train and test data for the category and non category\n",
    "     for instance, 1000 Civil verdicts will yield a 70%-30% division.\n",
    "    \n",
    "    :returns a data frame with only id and verdict text as well.\n",
    "    \n",
    "    keep in mind that a verdict can, and will, classify as two categories if it exists on both folders\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # dataframes initialization\n",
    "    verdicts_train_df_input_category = pd.DataFrame(columns = [\"Veredict_ID\", \"Verdict_Text\", \"Category\"])\n",
    "    verdicts_test_df_input_category = pd.DataFrame(columns = [\"Veredict_ID\", \"Verdict_Text\", \"Category\"])\n",
    "    verdicts_train_df_not_input_category = pd.DataFrame(columns = [\"Veredict_ID\", \"Verdict_Text\", \"Category\"])\n",
    "    verdicts_test_df_not_input_category = pd.DataFrame(columns = [\"Veredict_ID\", \"Verdict_Text\", \"Category\"])\n",
    "    temp_df_cat = pd.DataFrame(columns = [\"Veredict_ID\", \"Verdict_Text\", \"Category\"])\n",
    "    temp_df_not_cat = pd.DataFrame(columns = [\"Veredict_ID\", \"Verdict_Text\", \"Category\"])\n",
    "    df_tuple = [temp_df_cat,temp_df_not_cat]\n",
    "    \n",
    "    # tuple initialization\n",
    "    # index 1 is the category df, 0 is the opposite\n",
    "    for file in os.scandir(input_path):\n",
    "        if file.is_dir():\n",
    "            dir_name = str(os.path.basename(file)).split(\" - \")[0]\n",
    "            cur_cat = 0\n",
    "            if dir_name == input_category:\n",
    "                cur_cat = 1\n",
    "            for verdict in os.scandir(file):\n",
    "                if verdict.is_dir():\n",
    "                    for sub_folder in os.scandir(verdict):\n",
    "                        df_tuple[cur_cat] = df_tuple[cur_cat].append(make_temp_df(sub_folder,cur_cat),ignore_index = True)\n",
    "                else:\n",
    "                    df_tuple[cur_cat] = df_tuple[cur_cat].append(make_temp_df(verdict,cur_cat),ignore_index = True)\n",
    "\n",
    "    # making train-test split from the pre initialized tuple\n",
    "    verdicts_train_df_input_category,verdicts_test_df_input_category = train_test_split(df_tuple[1], test_size=desired_test_size)\n",
    "    verdicts_train_df_not_input_category,verdicts_test_df_not_input_category = train_test_split(df_tuple[0], test_size=desired_test_size)\n",
    "    \n",
    "    # adjusting the size of each df\n",
    "    if verdicts_train_df_input_category.shape[0] > verdicts_train_df_not_input_category.shape[0]:\n",
    "        verdicts_train_df_input_category = verdicts_train_df_input_category.sample(verdicts_train_df_not_input_category.shape[0])\n",
    "    else:\n",
    "        verdicts_train_df_not_input_category = verdicts_train_df_not_input_category.sample(verdicts_train_df_input_category.shape[0])\n",
    "    \n",
    "    if verdicts_test_df_input_category.shape[0] > verdicts_test_df_not_input_category.shape[0]:\n",
    "        verdicts_test_df_input_category = verdicts_test_df_input_category.sample(verdicts_test_df_not_input_category.shape[0])\n",
    "    else:\n",
    "        verdicts_test_df_not_input_category = verdicts_test_df_not_input_category.sample(verdicts_test_df_input_category.shape[0])\n",
    "    \n",
    "    # populating the returned df\n",
    "    returned_train_df = verdicts_train_df_input_category.append(verdicts_train_df_not_input_category,ignore_index=True)\n",
    "    returned_test_df = verdicts_test_df_input_category.append(verdicts_test_df_not_input_category,ignore_index=True)\n",
    "    \n",
    "    # returning the full dfs and the id-text only variable as well\n",
    "    return returned_train_df,returned_test_df,returned_train_df.drop([\"Veredict_ID\", \"Verdict_Text\"],axis=1),returned_test_df.drop([\"Veredict_ID\", \"Verdict_Text\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_verdict_summary_and_id(path:str):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    extracts verdict summary and id from a specified verdict\n",
    "    \n",
    "    :param path - a string that holds the verdict path\n",
    "    \n",
    "    :returns the verdict summary-string\n",
    "    \n",
    "    :returns the verdict id-string\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    with open(path,\"r\",encoding=\"utf-8\") as json_file:\n",
    "        json_dict = json.load(json_file)\n",
    "        verdict_summary = json_dict[\"_source\"][\"doc\"][\"Doc Details\"][\"סיכום\"]\n",
    "        verdict_id = json_dict[\"_id\"]\n",
    "    return verdict_summary,verdict_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_temp_df(path:str, cur_cat:str):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    makes temporary df which holds the current extracted verdict and summary\n",
    "    \n",
    "    :param path - a string that holds the verdict path\n",
    "    \n",
    "    :param cur_cat - a string the holds the current category\n",
    "    \n",
    "    :returns a data frame that corresponds to the main data frame structre\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    cur_verdict,cur_id = get_verdict_summary_and_id(path)\n",
    "    \n",
    "    return pd.DataFrame([[cur_id,cur_verdict,cur_cat]],columns=[\"Veredict_ID\", \"Verdict_Text\", \"Category\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_category = 'International law'\n",
    "# input_path = 'C:/Users/Itai/HebrewCourtVerdictsAnalyzer/ML/data/readytoclassify'\n",
    "# desired_test_size = 0.3 \n",
    "# a,b,c,d = create_train_test_of_specified_verdict_category(input_category,input_path, desired_test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(a.shape)\n",
    "# print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(b.sample(40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clean_text(text,stopwords_path):\n",
    "#     text_splitted_to_chars = [char for char in text if char not in string.punctuation]\n",
    "#     joined = ''.join(text_splitted_to_chars)\n",
    "#     #print(joined)\n",
    "#     stopwords = list()\n",
    "#     with open(stopwords_path,\"r\",encoding=\"utf-8\") as csv_file:\n",
    "#         csv_lines = csv.reader(csv_file,delimiter=',')\n",
    "#         stopwords = list(csv_lines)\n",
    "#     return [word for word in joined.split() if word not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text_no_stopwords(text:str):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    eliminates stopwords only \n",
    "    \n",
    "    :param text - a string to work on\n",
    "    \n",
    "    :returns a cleaned text without punctuation\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    text_splitted_to_chars = [char for char in text if char not in string.punctuation]\n",
    "    joined = ''.join(text_splitted_to_chars)\n",
    "   \n",
    "    return joined.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def apply_regex_rules_on_naming_csv(self, replace_with_this_str: str, input_name: str, csv_path: str):\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        Adds to every name hebrew prefixes that might exists on the data.\n",
    "\n",
    "        This method is very expansive and not recommended when not necessary.\n",
    "\n",
    "        :param replace_with_this_str - the string to be replaced with\n",
    "\n",
    "        :param input_name - name string\n",
    "\n",
    "        :param csv_path - the csv that contains the names to be subtracted from each and every matched column\n",
    "\n",
    "\n",
    "        :returns the element after subtracting matched words\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # initalization\n",
    "        updated_name = input_name\n",
    "        names_list = list()\n",
    "        rgx_list = list()\n",
    "\n",
    "        # open the csv file with the words to eliminate\n",
    "        with open(csv_path, \"r\", encoding='utf-8') as csv_file:\n",
    "\n",
    "            names_list = csv.reader(csv_file, delimiter=',')\n",
    "\n",
    "            names = [row[0] for row in names_list]\n",
    "\n",
    "            # add selcted prefixes\n",
    "            for name in names:\n",
    "                rgx_list.append(str.format(\"ו?\" + name))\n",
    "                rgx_list.append(str.format(\"ל?\" + name))\n",
    "                rgx_list.append(str.format(\"כ?ש?\" + name))\n",
    "                rgx_list.append(str.format(\"ה?\" + name))\n",
    "                rgx_list.append(str.format(\"ב?\" + name))\n",
    "                rgx_list.append(str.format(\"מ?\" + name))\n",
    "                rgx_list.append(str.format(\"ש?\" + name))\n",
    "                rgx_list.append(str.format(\"כ?\" + name))\n",
    "                rgx_list.append(name)\n",
    "\n",
    "                if len(name.split()) > 1:\n",
    "                    rgx_list.append(str.format(name.split()[0] + '-' + name.split()[1]))\n",
    "\n",
    "                if len(name.split('-')) > 1:\n",
    "                    rgx_list.append(str.format(name.split('-')[0] + ' ' + name.split('-')[1]))\n",
    "\n",
    "            for rgx_match in rgx_list:\n",
    "                # take only specific words - not substrings, \\\\b is the word border.\n",
    "                pattern = re.compile(str.format(\"\\\\b{0}\\\\b\", rgx_match))\n",
    "                updated_name = re.sub(pattern, replace_with_this_str, input_name)\n",
    "\n",
    "        after_elimination = ' '.join(updated_name.split())\n",
    "\n",
    "        return after_elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clean_text(text):\n",
    "#     text_splitted_to_chars = [char for char in text if char not in string.punctuation]\n",
    "#     joined = ''.join(text_splitted_to_chars)\n",
    "    \n",
    "#     text_splitted_to_chars = [char for char in text_splitted_to_chars if char not in string.digits]\n",
    "#     joined = ''.join(text_splitted_to_chars)\n",
    "\n",
    "#     after_stopwords = apply_regex_rules_on_naming_csv('',joined,'C:/Users/Itai Ofir/HebrewCourtVerdictsAnalyzer/ML/extensive_stopwords_after_filter.csv')\n",
    "        \n",
    "#     return after_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text:str, stopwords_path:str, naming_path:str):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    cleans given text\n",
    "    \n",
    "    eliminates all matched occurences found on the naming and stopwords files from the given string\n",
    "    \n",
    "    applies hebrew prefixes when searching\n",
    "    \n",
    "    :param text - the given text string\n",
    "    \n",
    "    :param stopwords_path - the path of the stopwords file\n",
    "    \n",
    "    :param naming_path - the path of the common namings file\n",
    "    \n",
    "    :returns the text after elimination\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    text_splitted_to_chars = [char for char in text if char not in string.punctuation]\n",
    "    joined = ''.join(text_splitted_to_chars)\n",
    "    \n",
    "    text_splitted_to_chars = [char for char in text_splitted_to_chars if char not in string.digits]\n",
    "    joined = ''.join(text_splitted_to_chars)\n",
    "    \n",
    "    after_stopwords = apply_regex_rules_on_naming_csv('',joined,stopwords_path)\n",
    "    after_naming = apply_regex_rules_on_naming_csv('',after_stopwords,naming_path)\n",
    "    \n",
    "    return after_naming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#after = clean_text(\"איתי הלך לטיול , הוא גם עו'ד גם עוד וגם שופט למרות',- שה352וא חזק\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_best_n_gram_for_each_category(input_path,categories,n_grams,dest_path):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    checks the best ngram for every category\n",
    "    \n",
    "    tries all of values stored on 'n_grams' dict\n",
    "    \n",
    "    after the precedure dumps the results text to file on the dest_apth\n",
    "    \n",
    "    :param input_path - a string of the path where the ready to clasiify verdict are present and ordered.\n",
    "    \n",
    "    :param cateogires - a list of strings that represents the category names\n",
    "    \n",
    "    :param n_grams - a list of round numbers that will be applied as test input for the vectorizer\n",
    "    \n",
    "    :param dest_path - a string of the destination path - on that path the results will be written\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    for cat in categories:\n",
    "        path=dest_path+'/'+cat+'.txt'\n",
    "        with open(path,'w',encoding='utf-8') as file:\n",
    "            for n_gram_val in n_grams:\n",
    "                train,test,y_train,y_test = create_train_test_of_specified_verdict_category(cat,input_path)\n",
    "                model_series = []\n",
    "                vec = TfidfVectorizer(ngram_range = (n_gram_val,n_gram_val))\n",
    "                transformed = vec.fit_transform(train[\"Verdict_Text\"])\n",
    "                model = MultinomialNB().fit(transformed,y_train.to_numpy(dtype=float).ravel())\n",
    "                test_transformed = vec.transform(test[\"Verdict_Text\"])\n",
    "                y_test_predict = model.predict(test_transformed)\n",
    "                file.write(str.format('\\nn_gram val : {0} \\n{1}\\n',n_gram_val,classification_report(y_test.to_numpy(dtype=float).ravel(),y_test_predict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_dump_model_and_tfidf_vectorizer(category:str, input_path:str, model_destination_path:str,tfidf_destination_path:str ,desired_n_gram, test_size):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    trains a specific category model and with a specific n-gram and dump it to the destination\n",
    "    \n",
    "    :param category - a string that holds the current category\n",
    "    \n",
    "    :param input_path - a string that holds the root folder of the categories-ordered data\n",
    "    \n",
    "    :param destination_path - a string that holds the path of the dumped model\n",
    "    \n",
    "    :param desired_n_gram - a number with the optimal n_gram for that category\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    train,test,y_train,y_test = create_train_test_of_specified_verdict_category(category,input_path,test_size)\n",
    "    vec = TfidfVectorizer(ngram_range = (desired_n_gram,desired_n_gram))\n",
    "    transformed = vec.fit_transform(train[\"Verdict_Text\"])\n",
    "    model = MultinomialNB().fit(transformed,y_train.to_numpy(dtype=float).ravel())\n",
    "    \n",
    "    with open(model_destination_path,'wb') as model_file:\n",
    "        pickle.dump(model,model_file)\n",
    "        \n",
    "    with open(tfidf_destination_path,'wb') as tfidf_file:\n",
    "        pickle.dump(vec,tfidf_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def automate_train_based_on_specific_ngram(categories, input_path:str, destination_path:str):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    uses the ngram check that has been done for each category and applies the best ngram for each category\n",
    "    \n",
    "    then dumps the model to the destination folder\n",
    "    \n",
    "    :param categoires - a list of strings that holds the categories\n",
    "    \n",
    "    :param input_path - a string of the root readytoclassify folder\n",
    "    \n",
    "    :param destination_path - a string of the destination folder\n",
    "    \n",
    "    \"\"\"\n",
    "    count = 1\n",
    "    try:\n",
    "        \n",
    "        for category in categories:\n",
    "            \n",
    "            print(str(count)+' / '+ str(len(categories)))\n",
    "            \n",
    "            if category == 'Administrative':\n",
    "                train_and_dump_model_and_tfidf_vectorizer(category, input_path, destination_path+'/'+category+'.pkl',destination_path+'/'+category+'.tfidf', 9, 0.3)\n",
    "            \n",
    "            elif category == 'Civil':\n",
    "                train_and_dump_model_and_tfidf_vectorizer(category, input_path, destination_path+'/'+category+'.pkl',destination_path+'/'+category+'.tfidf', 9, 0.3)\n",
    "            \n",
    "            elif category == 'Constitutional':\n",
    "                train_and_dump_model_and_tfidf_vectorizer(category, input_path, destination_path+'/'+category+'.pkl',destination_path+'/'+category+'.tfidf', 4, 0.3)\n",
    "            \n",
    "            elif category == 'Criminal':\n",
    "                train_and_dump_model_and_tfidf_vectorizer(category, input_path, destination_path+'/'+category+'.pkl',destination_path+'/'+category+'.tfidf', 6, 0.3)\n",
    "    \n",
    "            elif category == 'Family':\n",
    "                train_and_dump_model_and_tfidf_vectorizer(category, input_path, destination_path+'/'+category+'.pkl',destination_path+'/'+category+'.tfidf', 8, 0.3)\n",
    "                    \n",
    "            elif category == 'International law':\n",
    "                train_and_dump_model_and_tfidf_vectorizer(category, input_path, destination_path+'/'+category+'.pkl',destination_path+'/'+category+'.tfidf', 9, 0.3)       \n",
    "                  \n",
    "            elif category == 'Labor and Employment':\n",
    "                train_and_dump_model_and_tfidf_vectorizer(category, input_path, destination_path+'/'+category+'.pkl',destination_path+'/'+category+'.tfidf', 7, 0.3)\n",
    "                    \n",
    "            elif category == 'National security, military, and the territories':\n",
    "                train_and_dump_model_and_tfidf_vectorizer(category, input_path, destination_path+'/'+category+'.pkl',destination_path+'/'+category+'.tfidf', 2, 0.3)\n",
    "                    \n",
    "            elif category == 'Religious':\n",
    "                train_and_dump_model_and_tfidf_vectorizer(category, input_path, destination_path+'/'+category+'.pkl',destination_path+'/'+category+'.tfidf', 8, 0.3)      \n",
    "                  \n",
    "            elif category == 'Social security, Health Insurance, Pension':\n",
    "                train_and_dump_model_and_tfidf_vectorizer(category, input_path, destination_path+'/'+category+'.pkl',destination_path+'/'+category+'.tfidf', 7, 0.3)\n",
    "            \n",
    "            count += 1\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# input_path = 'C:/Users/Itai/HebrewCourtVerdictsAnalyzer/ML/data/readytoclassify'\n",
    "# categories = ['Family','Labor and Employment','Constitutional','Administrative','Civil','Criminal','International law','National security, military, and the territories','Religious','Social security, Health Insurance, Pension']\n",
    "# n_gram = [1,2,3,4,5,6,7,8,9,10]\n",
    "# dest_path = 'C:/Users/Itai/HebrewCourtVerdictsAnalyzer/ML/data'\n",
    "# check_best_n_gram_for_each_category(input_path,categories,n_gram,dest_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_path = 'C:/Users/Itai/HebrewCourtVerdictsAnalyzer/ML/data/readytoclassify'\n",
    "# categories = ['Family','Labor and Employment','Constitutional','Administrative','Civil','Criminal','International law','National security, military, and the territories','Religious','Social security, Health Insurance, Pension']\n",
    "# dest_path = 'C:/Users/Itai/HebrewCourtVerdictsAnalyzer/ML/data/models'\n",
    "# automate_train_based_on_specific_ngram(categories,input_path,dest_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_classifiers(input_path:str):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    loads the classifier from the given path and returns a dictionary with the category name as key\n",
    "    and the model itself as the value\n",
    "    \n",
    "    :param input_path - a string the represnets the models folder\n",
    "    \n",
    "    :returns string-model and string-tfidf dictionary\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    models_dict = dict()\n",
    "    tfidf_dict = dict()\n",
    "    \n",
    "    for file in os.scandir(input_path):\n",
    "        \n",
    "        if os.path.isfile(file):\n",
    "            \n",
    "            with open(file,'rb') as pickle_file:\n",
    "                    \n",
    "                    cur_model = pickle.load(pickle_file)\n",
    "            \n",
    "                    if os.path.basename(file).find('.pkl') != -1:\n",
    "                        \n",
    "                        current_category = os.path.basename(file).split('.pkl')[0]\n",
    "                        models_dict[current_category] = cur_model\n",
    "                    \n",
    "                    if os.path.basename(file).find('.tfidf') != -1:\n",
    "        \n",
    "                        current_category = os.path.basename(file).split('.tfidf')[0]   \n",
    "                        tfidf_dict[current_category] = cur_model\n",
    "    \n",
    "    return models_dict, tfidf_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "models,tfidfs = load_classifiers('C:/Users/Itai/HebrewCourtVerdictsAnalyzer/ML/data/models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models['Civil']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Administrative', 'Civil', 'Constitutional', 'Criminal', 'Family', 'International law', 'Labor and Employment', 'National security, military, and the territories', 'Religious', 'Social security, Health Insurance, Pension'])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(ngram_range=(9, 9))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidfs['Civil']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Administrative', 'Civil', 'Constitutional', 'Criminal', 'Family', 'International law', 'Labor and Employment', 'National security, military, and the territories', 'Religious', 'Social security, Health Insurance, Pension'])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidfs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_to_ngram = {'Administrative':9,\n",
    "                          'Civil':9,\n",
    "                          'Constitutional':4,\n",
    "                          'Criminal':6,\n",
    "                          'Family':8,\n",
    "                          'International law':9,\n",
    "                          'Labor and Employment':7,\n",
    "                          'National security, military, and the territories':2,\n",
    "                          'Religious':8,\n",
    "                          'Social security, Health Insurance, Pension':7\n",
    "                         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(verdict_summary:str, models:dict, tfidfs:dict, category_to_ngram:dict):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    passing the input verdict string as the prediction input for all of the pre-trained models\n",
    "    \n",
    "    the highest probability will be the verdict category\n",
    "    \n",
    "    :param verdict_summary - a string of the verdict summary\n",
    "    \n",
    "    :param models - category to model dictionary\n",
    "    \n",
    "    :param tfidfs - category to tfidf\n",
    "    \n",
    "    :param - category_to_nagram - category to ngram dictionary\n",
    "    \n",
    "    :returns - the chosen category string\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    category_to_score = dict()\n",
    "    score_to_category = dict()\n",
    "    \n",
    "    for category,model in zip(models.keys(),models.values()):\n",
    "        \n",
    "        cur_ngram = category_to_ngram[category]\n",
    "        cur_vectorizer = tfidfs[category]\n",
    "        transformed = cur_vectorizer.transform([verdict_summary])\n",
    "        cur_prob = model.predict_proba(transformed)\n",
    "        value = cur_prob[0][1]\n",
    "        category_to_score[category] = value\n",
    "        score_to_category[value] = category\n",
    "    \n",
    "    max_prob = max(category_to_score.values())\n",
    "    \n",
    "    return score_to_category[max_prob]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Religious\n"
     ]
    }
   ],
   "source": [
    "text = \"בנסיבות העניין, אין מקום להורות על השבת האגרה לפי תקנות בתי-המשפט (אגרות), התשס\\\"ז-2007. בהליך שבכותרת התקיים דיון לפני מותב של שלושה שופטים. אף שטענות הצדדים לגוף המחלוקת לא נשמעו באותו דיון, נדרש הרכב השופטים ללמוד את התיק עובר לדיון, והתיק זכה להקצאת זמן שיפוטי ביומנו העמוס של בית המשפט. מפרוטוקול הדיון עולה כי בפתח הישיבה שהתקיימה במעמד הצדדים, התייחס הרכב השופטים למאפייניו של התיק לאחר שקרא את כתבי-בית-הדין שבו, והמליץ למערערת לחזור בה מערעורה. כך אמנם אירע. אמת, דחיית הערעור בהסכמת המערערת חסכה את הצורך בשמיעת טענות הצדדים לגוף המחלוקת ובמתן הכרעה שיפוטית. עם זאת, בשים לב לשלב הדיוני בו נדחה הערעור ולהיקף השירות השיפוטי עד אותו שלב, לא מצאתי עילה שבדין להורות על השבת האגרה (ראו: תקנה 6(ב) בצירוף עם תקנה 15 לתקנות בתי המשפט (אגרות), התשס\\\"ז-2007; כן ראו: ע\\\"א 6802/09 קמינצקי נ' הוועדה המקומית לתכנון ובניה להבים (לא פורסם, 26.1.2011)). אשר על כן, הבקשה להשבת האגרה נדחית.\\nניתנה היום, י\\\"ד בסיוון תשע\\\"ב (4.6.2012).\\nדנה כהן-לקח, שופטת\"\n",
    "text2 = \"1. לא ראינו מקום להתערב בעונש שהוטל על המערער, למעט עניין אחד הנוגע למאסר על תנאי שהוטל.\\n2. המערער הודה במסגרת הסדר טיעון בעבירה של חבלה חמורה בנסיבות מחמירות וכן בהחזקת סמים לצריכה עצמית. מדובר בעבירה קשה של אלימות. המערער שלף סכין ודקר את המתלונן מספר פעמים וגרם לו לחתך ארוך ועמוק, בבסיס קשת הצלעות משמאל, פצעי דקירה בחלל הצפק חתכים בבית השחי ועוד. המתלונן עבר ניתוח בהרדמה כללית.\\n3. בגין שתי העבירות הוטל על המערער עונש של חמישים ושניים חודשי מאסר, מתוכם 40 חודשי מאסר בפועל והיתרה - שניים עשר חודשים - על תנאי למשך שנתיים מיום שחרורו, אם המערער יורשע בעבירת אלימות או בכל עבירה על פי פקודת הסמים המסוכנים. הופעל גם במצטבר מאסר על תנאי של שישה חודשים. בנוסף הוטל פיצוי למתלונן של 7,000 ש\\\"ח.\\n4. בשים לב להרשעותיו הקודמות של המערער ולחומרת הפציעה העונש אינו חמור כלל ועיקר ואנו דוחים את הערעור. עם זאת, בהסכמת המדינה אנו קובעים כי התנאי לא יחול על עבירה של החזקת סם לצריכה עצמית.\\nניתן היום, כ\\\"ו תשרי, תשע\\\"א (4.10.2010).\"\n",
    "text3 = \"השופט נ' הנדל:\\n1. מונח בפנינו ערעור על פסק דינו של בית המשפט המחוזי בתל אביב יפו (כב' סגן הנשיא, ד\\\"ר עודד מודריק) בת\\\"פ 4939-03-13, בו הורשע המערער בעבירה של החזקת סם שלא לצריכה עצמית, לפי סעיפים 7(א) ו 7(ג) לפקודת הסמים המסוכנים [נוסח חדש], התשל\\\"ג-1973. המערער נדון למאסר בפועל של 42 חודשים, ולכך נוספה הפעלת מאסר על תנאי של 10 חודשים שנגזרו עליו בתיק קודם. סה\\\"כ נגזרו על המערער מאסר בפועל של 52 חודשים, שנה וחצי נוספת של מאסר על תנאי, וקנס בסך 5,000 ₪ או חודשיים מאסר תמורתו.\\nבפסק הדין בערכאה קמא נקבע כי למרות שמערך הראיות הקיים הינו נסיבתי, הן אמינות ומהימנות. עדויות שוטרי הסיור שכנעו את בית המשפט כי הם ראו את המערער זורק דבר נוצץ לצד, וכי דבר זה נמצא ממש לאחר מכן, במקום שצפוי היה להימצא. בית המשפט דחה תרחישים אחרים שהוצעו על ידי הסניגור, כגון הטענה כי הסמים היו שם עוד לפני כן, בשל אי הסבירות לכך שחבילת סמים בשווי של כ 20,000 ₪ תונח זרוקה בסמטה נטושה. חיזוק לגרסת התביעה נמצא בתגובת המערער לעיכובו על ידי השוטרים, כפי שיובהר בהמשך. נקבע כי מארג הראיות הכולל מציג תמונה שממנה עולה אשמתו של המערער מעבר לספק סביר בעבירת החזקת הסם שלא לצריכה עצמית.\\n3. עולה מהחומר כי המערער נצפה על ידי שוטרי הסיור כשהוא משליך חפץ כסוף מידו, בשעת לילה מאוחרת, בסמוך לסמטה חשוכה. מיד לאחר מכן, בחיפוש קצר במרחק של כמה מטרים, נמצאת חבילת סם עטופה בנייר כסף בסמטה קרובה. לא רק זאת, אלא שכשנשאל המערער מדוע השליך את חבילת הסמים, משך בכתפיו והביט לשמיים, ולא הכחיש את המעשה. בחקירתו, ולאחר מכן בבית המשפט, לא הצליח המערער להניח גרסה עובדתית אחרת שתניח את הדעת. הצטברות כל הראיות לעיל מבססת את אשמתו של המערער מעבר לספק סביר, כפי שקבעה הערכאה קמא.\\nבצורה ממוקדת, מעלה הסניגור שתי טענות: האחת היא כי עדויותיהם של שוטרי הסיור מלאות סתירות, וכי דו\\\"חות הפעולה תואמו ביניהם. ביסוד טענה זו ניסיון לערער את אמינות העדויות של השוטרים. האחרת הינה כי הנמקתו של בית משפט קמא קצרה ביותר. טענות אלו הינן בעלות משקל, ודורשות התייחסות ובחינה. ברם, אין בכוחן לעורר ספק סביר במסגרת תיק זה. אסביר.\\nבאשר לדו\\\"חות השוטרים – עולה כי לכל הפחות אנשי המשטרה שוחחו ביניהם על האירוע טרם כתיבת תיאור המקרה על ידי כל שוטר בנפרד. חמור מכך, אחד מהדו\\\"חות מתייחס לדו\\\"חות פעולה של השוטרים האחרים שהיו במקום האירוע. מצב זה מעורר קושי, ואף קושי של ממש. מצופה כי כל שוטר יכתוב בעצמו את דו\\\"ח הפעולה. כוחו של הדו\\\"ח שהוא מהווה מעין תיעוד ישיר בסמוך לאירוע. אין בו מקום לסיעור מוחות, או להשלמה משותפת של פרטים שהתרחשו באירוע. דו\\\"ח פעולה שנכתב על ידי בעל תפקיד בסיום אירוע מהווה מקור מידע חשוב המשמש במקרים רבים לבירור האמת. תהליך בדיקה בין השוטרים, מעין סימפוזיון זוטא, עלול לפגוע במהימנות הנכתב, ואף מעבר לכך. הראציונל בעריכת הדו\\\"ח הוא הרצון לדייק, תוך הכרה בכך ששוטר עשוי להיות מעורב באירועים רבים, ולהעיד על האירוע הפרטני חודשים ארוכים לאחר המקרים. ההכרה בקושי שמלווה את תפקיד השוטר צועדת יד ביד עם הדרישה כי יקפיד שגרסתו תהיה גרסתו, ולא גרסתם. דווקא משום כך, לו הייתה ההרשעה מבוססת על הדו\\\"חות בלבד, היה מקום לשקול היטב את טענת הסניגור. ברם, בענייננו, הכרעת הדין מבוססת על מספר אדנים.\\nראשית כאמור, המערער אינו מכחיש כי ביצע תנועת זריקה. אמנם הוא מכחיש שזרק דבר מה, אך אין הסבר לתנועה שביצע. מעבר לכך, הסם נמצא בקרבת מקום. לכך נוסיף כי מיד לאחר האירוע הגיב המערער באופן שממנו ניתן היה להבין כי הוא משלים עם העונש המגיע לו (הרים ידיו למעלה והסתכל לשמיים) ולא הכחיש את מעשהו. בנסיבות העניין יש בכך מעין ראשית הודיה. מעבר לכך, המערער אף שלח מבטים שוב ושוב לכיוון הסמטה בה נתפסו הסמים.\\nסיכומו של דבר – נדמה כי הכרעת הדין מבוססת כנדרש. ההרשעה אינה נשענת לבדה על דו\\\"חות השוטרים, אלא כאמור על נתונים מחוץ למעגל פעילות המשטרה, כגון מקום תפיסת הסמים, ותגובת המערער לביצוע המעצר.\\n5. הייתי מציע לחבריי לדחות את הערעור על שני חלקיו.\\nהשופט א' שהם:\\nאני מסכים.\\nהשופטת ע' ברון:\\nאני מסכימה.\\nאשר על כן, הוחלט כאמור בפסק דינו של השופט נ' הנדל.\\nניתן היום, כ\\\"ב בסיון התשע\\\"ה (9.6.2015).\"\n",
    "text4 = \"השופט ח' מלצר:\\n1. עניינה של העתירה שלפנינו בהליך בחירת מנהל לבתי הדין הרבניים. העתירה הוגשה בעיצומו של ההליך, שהסתיים בינתיים במינויו של הרב שלמה דיכובסקי (להלן: הרב דיכובסקי) כמנהל קבוע לבתי הדין הרבניים עד לשנת 2014, לאחר ששימש בתפקיד במינוי זמני משך כששה חודשים. העותרים קראו, ועודם קוראים, לביטולו של הליך הבחירה, המצוי בתחום אחריותו של שר המשפטים, הוא המשיב. העותרים מבקשים עוד כי נפרש את סעיף 13 לחוק הדיינים, התשכ\\\"ט-1969 (להלן: חוק הדיינים), שמכוחו ממונה מנהל בתי הדין הרבניים, כמאפשר גם לנשים להגיש מועמדותן לתפקיד. לחלופין מבקשים העותרים כי נכריז על ביטול סעיף החוק ככל שהוא פוגע בזכויות חוקתיות. כן הם עותרים שנורה למשיב לפעול באופן אקטיבי כדי לגרום לנשים להגיש מועמדות למשרה, ובנוסף כי נורה לו ליתן ייצוג הולם לנשים בוועדה המייעצת שמינה לצורך הליך הבחירה.\\nלהלן נפרט את הנתונים הרלבנטיים להכרעה במכלול.\\n2. בתאריך 10.6.2010 החליטה הוועדה למינוי דיינים, בראשות שר המשפטים, לקצוב את כהונתו של מנהל בתי הדין הרבניים, הרב אליהו בן-דהן (להלן: הרב בן דהן), ששימש בתפקידו למעלה משני עשורים, כך שהלה יסיים את תפקידו בתאריך 11.8.2010. בעקבות זאת החל הליך למינוי מנהל חדש לבתי הדין הרבניים, מינוי המבוצע מכוחו של סעיף 13 לחוק הדיינים, הקובע כדלקמן:\\n\\\"(א) השר, בהסכמת נשיא בית הדין הרבני הגדול, יקבע, בתקנות או בהוראות מינהל, לפי הענין, את סדרי המינהל של בתי הדין הרבניים וימנה על ביצועם את אחד הדיינים או אדם הכשיר להיבחר רב עיר, שיהיה אחראי בפניהם; מינוי לפי סעיף קטן זה של מי שכשיר להיבחר רב עיר טעון אישור ועדת המינויים.\\n(ב) מנהל בתי הדין הרבניים שאיננו דיין, מינויו אינו טעון מכרז פומבי ודינו, לענין סעיף 17 ולענין חוק גימלאות לנושאי משרה ברשויות השלטון, התשכ\\\"ט-1969, כדין דיין.\\\"\\n3. אף שסעיף 13 הנ\\\"ל איננו מחייב לעשות כן, החליט השר להקים ועדה לאיתור מועמדים למשרת המנהל החדש (להלן: הוועדה המייעצת).\\n4. בעקבות האמור לעיל פנו העותרים לשר המשפטים במכתב שבו טענו כי עליו לפתוח את תפקיד מנהל בתי הדין הרבניים בפני נשים. זאת, לגישתם, מכוח הוראות חוק יסוד: חופש העיסוק, חוק יסוד: כבוד האדם וחירותו, חוק שיווי זכויות האשה, התשי\\\"א-1951 (להלן: חוק שיווי זכויות האשה), וחוק שוויון הזדמנויות בעבודה, התשמ\\\"ח-1988 (להלן: חוק שוויון הזדמנויות בעבודה). העותרים הוסיפו וטענו כי מינוי אשה לתפקיד מנכ\\\"ל בתי הדין הרבניים עשוי להיות צעד ראשון לתיקון מעמדן הנחות, לפי הנטען, של הנשים בבתי הדין הרבניים ואיזון לכך שכל הדיינים בבתי הדין הרבניים הם גברים. עוד דרשו העותרים מן המשיב כי בוועדה המייעצת שתתמנה לעניין איתור המועמדים לתפקיד יהיה ייצוג הולם לנשים.\\n5. בהמשך להתפתחויות הנ\\\"ל שר המשפטים מינה, בתאריך 22.7.2010, ועדה מייעצת, הכוללת ארבעה גברים (הרב ד\\\"ר רצון ערוסי, השופט (בדימ') יעקב שמעוני, הרב ד\\\"ר יעקב הדני, פרופ' אליאב שוחטמן) ואשה אחת (עו\\\"ד בת שבע שרמן-שני, המשמשת, בין היתר, כמנכ\\\"ל בארגון \\\"יד לאישה\\\", המסייע לנשים עגונות ומסורבות גט). למחרת היום פורסמה באתר לשכת הפרסום הממשלתית פנייה לאיתור מועמדים.\\n6. בתאריך 29.7.2010 הגישו העותרים עתירה לבית משפט זה, עתירה שקדמה לזו שלפנינו (בג\\\"ץ 5720/10; להלן: העתירה הקודמת). בעתירה הקודמת ביקשו העותרים כי בית המשפט יורה למשיב לפרש את סעיף 13 לחוק הדיינים באופן כזה המאפשר מינויה של אשה כמנהלת של בתי הדין הרבניים, ולחלופין יקבע כי סעיף חוק זה בטל ככל שהוא פוגע בזכויות חוקתיות. כן ביקשו העותרים כי בית משפט זה יורה על הרחבת ייצוג הנשים בוועדה המייעצת, נוכח החובה לייצוג הולם על פי סעיף 6 לחוק שיווי זכויות האשה.\\n7. העתירה הקודמת נדחתה על הסף בתאריך 17.8.2010 (מפי השופטים: א' גרוניס, מ' נאור ו-ע' פוגלמן). בעניין הסעד הנוגע למינויה של אִשה לתפקיד מנהלת בתי הדין הרבניים נקבע כי העתירה דנא היא מוקדמת מאחר שלפי הודעת המשיב טרם נעשתה בחינה ביחס לאלה שהגישו מועמדות לתפקיד, ולא נתקבלה כל החלטה בשאלה האם ניתן לפרש את סעיף 13 לחוק הדיינים כמאפשר מינוי אשה למשרה זו. בית המשפט הוסיף שלעותרים תהיה שמורה הזכות לפנות למשיב ואף לבית משפט זה, אם יהיה בכך צורך, לאחר שתתקבל ההחלטה בדבר המינוי.\\nאשר לסעד שעניינו ייצוג הולם של נשים בוועדה המייעצת נקבע כי העותרים לא מיצו את ההליכים לשינוי הרכב הוועדה וכן כי הם לא פירטו מדוע בנסיבות העניין מינויה של אִשה אחת מבין חמישה חברים בוועדה איננו מהווה ייצוג הולם.\\n8. בסמוך לפני ההכרעה בעתירה הקודמת, ומשפקעה בינתיים כהונתו של הרב בן דהן כמנהל בתי הדין הרבניים, מינה שר המשפטים את הרב דיכובסקי, דיין בקיצבה של בית הדין הרבני הגדול, למנהל בפועל של בתי הדין הרבניים. מינויו הוארך באופן זמני עד למחצית חודש פברואר 2011.\\n9. לאחר מתן פסק הדין בעתירה הקודמת נמשכו הליכי בחינת המועמדים, והעותרים התמידו בפניות למשיב לקידום אפשרות מינויה של אשה לתפקיד מנהלת בתי הדין הרבניים. עמדת המשיב היתה, בין היתר, שהוועדה המייעצת הונחתה לבחון את נתוניהם של כלל המועמדים, נשים כגברים, ואם יימצא כי כישוריה של מועמדת אשה דומים לאלה של המועמדים הגברים המתאימים ביותר – יבחן המשיב, יחד עם היועץ המשפטי לממשלה, את אפשרות מינויה של אשה לתפקיד.\\n12. בתאריך 1.3.2011, לאחר שלא הושגה הסכמה על מינוי מי מבין המועמדים המומלצים שהעבירה הוועדה המייעצת, מינה שר המשפטים את הרב דיכובסקי לתפקיד, בהסכמת נשיא בית הדין הרבני הגדול ובאישור הוועדה למינוי דיינים. תוקף המינוי נקבע עד לתאריך י\\\"ט באב התשע\\\"ד (15.8.2014). הודעה בדבר המינוי התפרסמה ברשומות בתאריך 12.4.2011 (י\\\"פ התשע\\\"א, עמ' 3276). שר המשפטים הודיע לרב דיכובסקי כי סופיות מינויו כפופה להכרעת בית משפט זה בעתירה.\\nטענות הצדדים\\n13. העותרים טוענים כי בהליך מינוי המנכ\\\"ל לבתי הדין הרבניים נפלו פגמים, המצדיקים את ביטולו.\\nבראש הראשון של עתירתם הם טוענים כי ראוי היה לפרש את סעיף 13 לחוק הדיינים (שצוטט בפיסקה 2 לעיל) באופן שלא יגביל את מועמדותן של נשים לתפקיד ויעלה בקנה אחד עם חוקי היסוד הנ\\\"ל וחוק שיווי זכויות האשה. לשיטת העותרים פרשנות שכזו צריכה להוביל למסקנה כי אין כל פגם בכשירותן של נשים לתפקיד מנהלת של בתי הדין הרבניים. לחלופין טוענים העותרים כי יש להכריז על בטלותו של סעיף 13 לחוק הדיינים, ככל שהוא פוגע בזכויות חוקתיות.\\nבראש השני של העתירה טוענים העותרים לפגמים בהליך בחינת המועמדים לתפקיד ובהליכי עבודתה של הוועדה המייעצת שפעלה בעניין, ובהם (לשיטת העותרים): אי מילוי החובה לפעול באופן אקטיבי לאיתור מועמדות ראויות למשרה, אי מילוי החובה לפעול לייצוג הולם של נשים בניהול בתי הדין הרבניים ואי מתן משקל מספק לעיקרון הייצוג השוויוני בהליך המינוי עצמו. עוד משיגים העותרים על כך שלא יושם עיקרון הייצוג ההולם גם בקביעת הרכב הוועדה המייעצת לשר המשפטים ונטען כי אין מנוס מלהורות למשיב למנות ועדת איתור חדשה, אשר מיוזמתה תפנה לנשים ראויות ותבחן את כל המועמדים על פי השיקולים השייכים לענין, לרבות השיקולים בדבר ייצוג הולם של נשים במגזר הציבורי בכלל ובמערכת בתי הדין הרבניים בפרט.\\nראשית מדגיש המשיב כי עם מינויו של הרב דיכובסקי למנהל קבוע של בתי הדין הרבניים השתנה המצב העובדתי, מושא העתירה, באופן ההופך את העתירה דנן לעיונית. המשיב מדגיש כי לרב דיכובסקי יש כישורים, רקע וניסיון רלבנטיים מיוחדים ויוצאי דופן לתפקיד, שמקנים לו עדיפות ניכרת על פני כל מועמד פוטנציאלי אחר לתפקיד, יהיה זה גבר או אשה, ואף העותרים אינם חולקים על כך. המשיב מסביר ומציין בהקשר זה כי הרב דיכובסקי כיהן כשמונה שנים כדיין בבית דין אזורי, כחמש שנים נוספות כאב בית דין אזורי וכ-19 שנים ומחצה – כדיין בבית הדין הרבני הגדול, כל זאת בנוסף לתקופת כהונתו הזמנית כמנהל בפועל של בתי הדין הרבניים. עוד שימש הרב דיכובסקי כמרצה מן החוץ באוניברסיטאות תל אביב ובר אילן. עמדת המשיב היא שתהא פרשנותו הנכונה של סעיף 13 לחוק הדיינים אשר תהא, הרי שבשים לב לכך שהעותרים אינם יכולים להצביע על מועמדת פוטנציאלית לתפקיד מנהל בתי הדין הרבניים שהיא בעלת \\\"כישורים דומים\\\" לאלה של הרב דיכובסקי – אין כל צורך להכריע במסגרת העתירה בטענות העותרים בנוגע לסעיף 13 הנ\\\"ל, או באשר לתחולת סעיף 6ג לחוק שיווי זכויות האשה ביחס למשרה זו, והטענות הופכות בהקשרים שלפנינו להשגות תיאורטיות גרידא.\\nעוד טוען המשיב כי דין העתירה להידחות על הסף מחמת שיהוי שנפל בהתנהלות העותרים, ומכיוון שהיה על העותרים לתקן את עתירתם לאחר מינויו של הרב דיכובסקי ולהוסיפו כמשיב לעתירה – דבר שהעותרים לא עשו.\\nהמשיב מוסיף עוד כי ממילא דין העתירה להידחות גם לגוף הדברים. לגבי הטענות בדבר הרכב הוועדה המייעצת, המשיב מדגיש כי זו מונתה באופן וולנטארי, מבלי שהיתה כל חובה שבדין לעשות כן, ובנסיבות אלה אף אם תתקבל טענת העותרים וייפתח מחדש הליך המינוי – אין כל הכרח כי תמונה ועדה חדשה.\\nבכל הנוגע לדרישת העותרים לפעולה אקטיבית מצד המשיב – לעודד נשים להגיש את מועמדותן למשרה, המשיב גורס כי מעולם לא ציין במודעות שפורסמו לציבור כי מדובר במשרה לגברים בלבד וכי אשה אחת אכן הגישה את מועמדותה. בהקשר זה שב ומדגיש המשיב כי אין כל מקום לפתוח עתה מחדש את הליך המינוי.\\n15. העותרים ביקשו להשיב לטענות המשיב בכתב ואמנם עשו כן, וגם הרחיבו דברים בעל פה לפנינו. טענתם העיקרית היא שחרף מינויו של הרב דיכובסקי (שהעותרים אינם טוענים כי קיימת מועמדת – או מועמד – שווי-כישורים לו) – לא הפכה עתירתם לעיונית. לגישתם – אין במינויו של אדם בעל כישורים מיוחדים, ככל שיהיו, כדי לייתר את הטענות בדבר חובת המשיב לקיים הליך שוויוני הפתוח בפני נשים וחובתו לפעול למען איתור אקטיבי של מועמדות. העותרים גורסים איפוא כי \\\"לא בטוח\\\" שתיקון העתירה הכרחי על מנת לדון בטענותיהם העקרוניות, הגם שהצהירו שאם בית משפט זה יסבור כי הדבר נחוץ – הם נכונים לבקש לתקן את עתירתם לצורך חידוד השאלות שנותרו עדיין שנויות במחלוקת.\\nלאחר סקירה זו של השתלשלות העניינים וטענות הצדדים הגיעה העת להכריע במכלול.\\nדיון והכרעה\\n16. לאחר שבחנתי את טענות הצדדים, אציע לחבריי לדחות את העתירה שלפנינו. אפרט עתה בתמציתיות את הנימוקים שבבסיס מסקנתי זאת, כאשר אפתח בטעם דיוני ואעבור לאחר מכן לטעם הענייני שבדבר.\\n17. מבחינה דיונית אכן נפל פגם בהתנהלות העותרים, עת לא צירפו כמשיב לעתירה את הרב דיכובסקי לאחר שהוא נבחר לכהן כמנהל הקבוע של בתי הדין הרבניים. בזמן הגשת העתירה המצב היה אמנם שונה, שכן טרם מונה איש לתפקיד ואולם משנמסרה לעותרים עובדת המינוי הם היו צריכים לצרף את הרב דיכובסקי כמשיב, בהיותו צד נוגע בדבר, שההחלטה בעתירה עלולה לפגוע בו (ויוזכר כי המשיב טען זאת מפורשות בתגובתו המקדמית). משלא עשו העותרים כן, אף שהיו להם די והותר הזדמנויות לתקן מחדל זה, הרי שדבק פגם משמעותי בעתירתם, שיש בו, כשלעצמו, כדי להביא לדחייתה (השוו: בג\\\"ץ 84/82 הסתדרות פועלי אגודת ישראל נ' השר לענייני דתות, פ\\\"ד לז(1) 813, 817-815 (1983); בג\\\"ץ 828/90 סיעת \\\"הליכוד\\\" במועצת עיריית חיפה נ' מועצת עיריית חיפה, פ\\\"ד מה(1) 506, 516 (1991); בג\\\"ץ 9402/03 בוכניק נ' המועצה האזורית לתכנון ובניה (לא פורסם, 18.3.2007), פיסקה 11 לפסק הדין; בג\\\"ץ 2592/10 פלוני נ' פקידת סעד לסדרי דין (לא פורסם, 26.4.2010)).\\n18. בנוסף לפגם הדיוני האמור, הרי שממילא אין מקום להעמיד כיום לבירור, במסגרת הנוכחית, את טענות העותרים במישור החוקתי, בכל הכרוך בפרשנותו הראויה של סעיף 13 לחוק הדיינים ואפשרות מינוייה של אשה לתפקיד בגדרו. זאת לא מחמת קיומו של מעשה עשוי (והרי המינוי הוכפף ממילא להכרעה בעתירה), כי אם משום שטענות אלה אכן הפכו עתה עיוניות, כפי שטען המשיב, שהרי בבחירה של הרב דיכובסקי למשרה אמנם מדובר במינוי של מי שאין חולק על כישוריו יוצאי הדופן והתאמתו לתפקיד. דומה שאף העותרים עצמם מסכימים לכך (ראו לדוגמה מכתבם מתאריך 11.5.2011, מש/3, כמו גם האמור בבקשתם לצו ביניים, בגדרה עתרו לכך שהרב דיכובסקי ימשיך לכהן בתפקיד – במינוי זמני). העותרים גם אינם טוענים כי האשה האחת שהגישה את מועמדותה לתפקיד (היא מנכ\\\"לית העותר 1) היא שוות כישורים לאלו של הרב דיכובסקי, שאז על פי טענתם היה מקום לבחון את האפשרות העקרונית למינוי אשה לתפקיד. באופן דומה – העותרים, המייצגים קשת רחבה של ארגונים הפועלים, בין היתר, לקידום מעמד הנשים ולמיגור קיפוחן ואפלייתן – אינם גורסים כי קיימת מועמדת כלשהי, אף אם לא הגישה מועמדותה לתפקיד, שכישוריה ומעלותיה דומים לאלו של הרב דיכובסקי לצורך התפקיד – מושא העתירה.\\n19. למעשה כל שנותר מעתירתם של העותרים הן השאלות העיוניות שהעלו, שעיקרן: האם ניתן לפרש את סעיף 13 לחוק הדיינים כמאפשר מינויה של אשה לתפקיד מנהלת בתי הדין הרבניים, ואם לא – האם יש מקום להורות על בטלותה של הוראה זו, ככל שהיא פוגעת בזכויות חוקתיות נטענות? טענות אלה של העותרים בדבר האפלייה המובנית, לדעתם, בחוק הדיינים ודאי מעלות שאלות מורכבות ומעניינות (עיינו: Martha Minow \\\"Should Religious Groups Ever Be Exempt From Civil Rights Laws?\\\" 48 Boston College Law Review 781, 801-808 (2007); John T. Noonan, Edward M. Gaffney Religious Freedom (3rd ed., 2011), 794-796; McClure v. Salvation Army, 460 F.2d 553 (5th Cir. 1972), cert. denied, 409 US 896 (1972); Equal Employment Opportunity Commission v. Mississippi College, 626 F. 2d 477 (5th Cir. 1980); Equal Employment Opportunity Commission v. Catholic University of America, 83 F. 3d 455 (D.C. Cir. 1996) ). ברי עם זאת שככל שמדובר בהליך בחירתו הנוכחי של מנהל בתי הדין הרבניים, הרי ששאלות אלה הן עיוניות, ואינן מצדיקות את הכרעתנו לעת הזו.\\n20. נוכח כל הטעמים המפורטים לעיל – אציע לחבריי כי נדחה את העתירה, בלא שנעשה בה צו להוצאות.\\nהשופט (בדימ') א' א' לוי:\\nאני מסכים.\\nהשופט י' דנציגר:\\nאני מסכים.\\nהוחלט כאמור בפסק דינו של השופט ח' מלצר.\\nניתן היום, א' בטבת, תשע\\\"ב (27.12.2011).\"\n",
    "res = classify(text4,models,tfidfs,category_to_ngram)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "יצחק אולשן\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('C:/Users/Itai/HebrewCourtVerdictsAnalyzer/ML/Pipeline Python Scripts/israel_supreme_court_judges.txt','r') as file:\n",
    "    with open('C:/Users/Itai/HebrewCourtVerdictsAnalyzer/ML/Pipeline Python Scripts/israel_court_judges.txt','w') as new_file:\n",
    "        lines = file.readlines()\n",
    "        print(lines[1])\n",
    "        for line in lines:\n",
    "            if len(line.split()) <= 3 and len(line.split()) > 1:\n",
    "                new_file.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:/Users/Itai/HebrewCourtVerdictsAnalyzer/ML/Pipeline Python Scripts/israel_court_judges.txt','r') as file:\n",
    "    lines = file.readlines()\n",
    "    \n",
    "    with open('C:/Users/Itai/HebrewCourtVerdictsAnalyzer/ML/Pipeline Python Scripts/israel_court_judges_fixed.txt','w') as nfile:\n",
    "\n",
    "        for line in lines:\n",
    "\n",
    "            splitted = line.split()\n",
    "            \n",
    "            if len(splitted) >= 3:\n",
    "                \n",
    "                corrected = f'{splitted[2]} {splitted[0]}-{splitted[1]}'\n",
    "\n",
    "            else:\n",
    "                corrected = f'{splitted[0]} {splitted[1]}'\n",
    "            \n",
    "            nfile.write(corrected+'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
