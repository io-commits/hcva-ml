{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This classification model is based on MultiNomialNB \n",
    "# Pay attention to cleanning procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "import csv\n",
    "import string\n",
    "import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the categorized data to classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_key_exists(input_key,input_collection):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    checks if key exists on the collection\n",
    "    \n",
    "    :param input_key - the key to search on the collection\n",
    "    :param input_collection - the collection\n",
    "    \n",
    "    :returns True if key exists, else False\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    key_found = False\n",
    "    for key in input_collection.keys():\n",
    "        if key == input_key:\n",
    "            key_found = True\n",
    "            break\n",
    "    \n",
    "    return key_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sub_categories_count(input_category:str, input_path:str):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    checks how many subcategories exists to an input category.\n",
    "    \n",
    "    :param input_category - a string describes the category\n",
    "    :param input_path - the verdicts files path\n",
    "    \n",
    "    :returns a dictionary which has the category names as keys and the occurences count as values\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    #initialization\n",
    "    category_dict = dict()\n",
    "    \n",
    "    # iterate on the files on the input path\n",
    "    for scanned_file in os.scandir(input_path):\n",
    "        \n",
    "        # look for directories only due to the fact that all the extracted verdicts\n",
    "        # are already have been set to the right directory tree\n",
    "        \n",
    "        if scanned_file.is_dir() == True:\n",
    "            \n",
    "            # split the directory name by ' - ' - that is how the justice department \n",
    "            # have been decided to seperate the category and the sub category\n",
    "            \n",
    "            dir_name = os.path.basename(scanned_file)\n",
    "            splitted_category = str(dir_name).split(\" - \")\n",
    "            \n",
    "            # check the len of the splitted catregory\n",
    "            # there are two main \n",
    "            if splitted_category[0] == input_category:\n",
    "                if len(splitted_category) == 3:\n",
    "                    for first_sub in os.scandir(scanned_file):\n",
    "                       \n",
    "                        if check_if_key_exists(splitted_category[1]+ \" - \" + splitted_category[2],category_dict):\n",
    "                            category_dict[splitted_category[1]+ \" - \" + splitted_category[2]] += 1\n",
    "                        else:\n",
    "                            category_dict[splitted_category[1]+ \" - \" + splitted_category[2]] = 1\n",
    "                else:\n",
    "                    for first_sub in os.scandir(scanned_file):\n",
    "                        \n",
    "                        if check_if_key_exists(splitted_category[1],category_dict):\n",
    "                            category_dict[splitted_category[1]] += 1\n",
    "                        else:\n",
    "                            category_dict[splitted_category[1]] = 1\n",
    "            \n",
    "    category_dict[input_category + \" Total\"] = sum(category_dict.values())\n",
    "    \n",
    "    return category_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_categories_count(input_path:str):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    counts the quantity of main categories\n",
    "    \n",
    "    :param input_path - a string holds the path to the root folder\n",
    "    \n",
    "    :returns a dictionary with the names of the \n",
    "     categories and the verdicts present for each and every of them\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # initalization\n",
    "    category_dict = dict()\n",
    "    \n",
    "    # iterate on the folder\n",
    "    for scanned_file in os.scandir(input_path):\n",
    "        \n",
    "        # look for directories only\n",
    "        if scanned_file.is_dir() == True:\n",
    "            \n",
    "            # look for the main category only, for example: 'Civil'\n",
    "            dir_name = os.path.basename(scanned_file)\n",
    "            splitted_category = str(dir_name).split(\" - \")\n",
    "            cur_category = splitted_category[0]\n",
    "            \n",
    "            # advance counter according to the findings\n",
    "            for sub_cat in os.scandir(scanned_file):\n",
    "                if check_if_key_exists(cur_category,category_dict):\n",
    "                    category_dict[cur_category] += 1\n",
    "                else:\n",
    "                    category_dict[cur_category] = 1\n",
    "    \n",
    "    return category_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dest_path = 'C:/Users/Itai Ofir/HebrewCourtVerdictsAnalyzer/ML/data/readytoclassify'\n",
    "# test_category = 'Civil'\n",
    "# result_sub_cat_dict = get_sub_categories_count(test_category,dest_path)\n",
    "# result_cat_dict = get_categories_count(dest_path)\n",
    "# print_dict(result_sub_cat_dict)\n",
    "# print(\" - - - - - - - - - - - - \")\n",
    "# print_dict(result_cat_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_dict(input_dict):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    prints given dictionary\n",
    "    \n",
    "    :param input_dict - dictionary\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    for key in input_dict:\n",
    "        print(key + \" : \" + str(input_dict[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_category = 'Administrative'\n",
    "# dest_path = 'C:/Users/Itai Ofir/HebrewCourtVerdictsAnalyzer/ML/data/readytoclassify'\n",
    "# calculate_required_categories_count_ratio(test_category,dest_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create train and test based on previous dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_train_and_test_frames(input_category,input_category_count_dictionary,verdicts_path):\n",
    "#     appereances_ratio_dict = input_category_count_dictionary.copy()\n",
    "#     total_tagged_verdicts = int(sum(input_category_count_dictionary.values()))\n",
    "#     for key,val in zip(input_category_count_dictionary.keys(),input_category_count_dictionary.values()):\n",
    "#         appereances_ratio_dict[key] = val/total_tagged_verdicts\n",
    "#     print_dict(appereances_ratio_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dest_path = 'C:/Users/Itai/HebrewCourtVerdictsAnalyzer/ML/data/readytoclassify'\n",
    "test_category = 'Civil'\n",
    "result_sub_cat_dict = get_sub_categories_count(test_category,dest_path)\n",
    "result_cat_dict = get_categories_count(dest_path)\n",
    "print_dict(result_sub_cat_dict)\n",
    "print(\" - - - - - - - - - - - - - - - - - - - - - \")\n",
    "print_dict(result_cat_dict)\n",
    "print(\" - - - - - - - - - - - - - - - - - - - - - \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creating train,test df of specified category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_test_of_specified_verdict_category(input_category:str,input_path:str, desired_test_size):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    based on the root directory tree, this method will make a data frame for \n",
    "    every category which has the exact amount of matched verdicts vs non matched.\n",
    "    for instance - 1000 'Civil' verdicts vs 1000 mixture of 'Administrative'\n",
    "    , 'Constitutional' and so on.\n",
    "    \n",
    "    :param input_category - a string that holds the category name - \n",
    "     Attention! this name must be identical to the name present on the root directory\n",
    "     \n",
    "    :param input_path - a string that holds the root directory path\n",
    "    \n",
    "    :param desired_test_size - a number between 0-1 that corresponds to the \n",
    "     precentage of test data that will be created and returned.\n",
    "     needless to say that will fix the train precentage as well.\n",
    "    \n",
    "    :returns a data frame for the train and test data for the category and non category\n",
    "     for instance, 1000 Civil verdicts will yield a 70%-30% division.\n",
    "    \n",
    "    :returns a data frame with only id and verdict text as well.\n",
    "    \n",
    "    keep in mind that a verdict can, and will, classify as two categories if it exists on both folders\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # dataframes initialization\n",
    "    verdicts_train_df_input_category = pd.DataFrame(columns = [\"Veredict_ID\", \"Verdict_Text\", \"Category\"])\n",
    "    verdicts_test_df_input_category = pd.DataFrame(columns = [\"Veredict_ID\", \"Verdict_Text\", \"Category\"])\n",
    "    verdicts_train_df_not_input_category = pd.DataFrame(columns = [\"Veredict_ID\", \"Verdict_Text\", \"Category\"])\n",
    "    verdicts_test_df_not_input_category = pd.DataFrame(columns = [\"Veredict_ID\", \"Verdict_Text\", \"Category\"])\n",
    "    temp_df_cat = pd.DataFrame(columns = [\"Veredict_ID\", \"Verdict_Text\", \"Category\"])\n",
    "    temp_df_not_cat = pd.DataFrame(columns = [\"Veredict_ID\", \"Verdict_Text\", \"Category\"])\n",
    "    df_tuple = [temp_df_cat,temp_df_not_cat]\n",
    "    \n",
    "    # tuple initialization\n",
    "    # index 1 is the category df, 0 is the opposite\n",
    "    for file in os.scandir(input_path):\n",
    "        if file.is_dir():\n",
    "            dir_name = str(os.path.basename(file)).split(\" - \")[0]\n",
    "            cur_cat = 0\n",
    "            if dir_name == input_category:\n",
    "                cur_cat = 1\n",
    "            for verdict in os.scandir(file):\n",
    "                if verdict.is_dir():\n",
    "                    for sub_folder in os.scandir(verdict):\n",
    "                        df_tuple[cur_cat] = df_tuple[cur_cat].append(make_temp_df(sub_folder,cur_cat),ignore_index = True)\n",
    "                else:\n",
    "                    df_tuple[cur_cat] = df_tuple[cur_cat].append(make_temp_df(verdict,cur_cat),ignore_index = True)\n",
    "\n",
    "    # making train-test split from the pre initialized tuple\n",
    "    verdicts_train_df_input_category,verdicts_test_df_input_category = train_test_split(df_tuple[1], test_size=desired_test_size)\n",
    "    verdicts_train_df_not_input_category,verdicts_test_df_not_input_category = train_test_split(df_tuple[0], test_size=desired_test_size)\n",
    "    \n",
    "    # adjusting the size of each df\n",
    "    if verdicts_train_df_input_category.shape[0] > verdicts_train_df_not_input_category.shape[0]:\n",
    "        verdicts_train_df_input_category = verdicts_train_df_input_category.sample(verdicts_train_df_not_input_category.shape[0])\n",
    "    else:\n",
    "        verdicts_train_df_not_input_category = verdicts_train_df_not_input_category.sample(verdicts_train_df_input_category.shape[0])\n",
    "    \n",
    "    if verdicts_test_df_input_category.shape[0] > verdicts_test_df_not_input_category.shape[0]:\n",
    "        verdicts_test_df_input_category = verdicts_test_df_input_category.sample(verdicts_test_df_not_input_category.shape[0])\n",
    "    else:\n",
    "        verdicts_test_df_not_input_category = verdicts_test_df_not_input_category.sample(verdicts_test_df_input_category.shape[0])\n",
    "    \n",
    "    # populating the returned df\n",
    "    returned_train_df = verdicts_train_df_input_category.append(verdicts_train_df_not_input_category,ignore_index=True)\n",
    "    returned_test_df = verdicts_test_df_input_category.append(verdicts_test_df_not_input_category,ignore_index=True)\n",
    "    \n",
    "    # returning the full dfs and the id-text only variable as well\n",
    "    return returned_train_df,returned_test_df,returned_train_df.drop([\"Veredict_ID\", \"Verdict_Text\"],axis=1),returned_test_df.drop([\"Veredict_ID\", \"Verdict_Text\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_verdict_summary_and_id(path:str):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    extracts verdict summary and id from a specified verdict\n",
    "    \n",
    "    :param path - a string that holds the verdict path\n",
    "    \n",
    "    :returns the verdict summary-string\n",
    "    \n",
    "    :returns the verdict id-string\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    with open(path,\"r\",encoding=\"utf-8\") as json_file:\n",
    "        json_dict = json.load(json_file)\n",
    "        verdict_summary = json_dict[\"_source\"][\"doc\"][\"Doc Details\"][\"סיכום\"]\n",
    "        verdict_id = json_dict[\"_id\"]\n",
    "    return verdict_summary,verdict_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_temp_df(path:str, cur_cat:str):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    makes temporary df which holds the current extracted verdict and summary\n",
    "    \n",
    "    :param path - a string that holds the verdict path\n",
    "    \n",
    "    :param cur_cat - a string the holds the current category\n",
    "    \n",
    "    :returns a data frame that corresponds to the main data frame structre\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    cur_verdict,cur_id = get_verdict_summary_and_id(path)\n",
    "    \n",
    "    return pd.DataFrame([[cur_id,cur_verdict,cur_cat]],columns=[\"Veredict_ID\", \"Verdict_Text\", \"Category\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_category = 'International law'\n",
    "input_path = 'C:/Users/Itai/HebrewCourtVerdictsAnalyzer/ML/data/readytoclassify'\n",
    "desired_test_size = 0.3 \n",
    "a,b,c,d = create_train_test_of_specified_verdict_category(input_category,input_path, desired_test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a.shape)\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(b.sample(40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clean_text(text,stopwords_path):\n",
    "#     text_splitted_to_chars = [char for char in text if char not in string.punctuation]\n",
    "#     joined = ''.join(text_splitted_to_chars)\n",
    "#     #print(joined)\n",
    "#     stopwords = list()\n",
    "#     with open(stopwords_path,\"r\",encoding=\"utf-8\") as csv_file:\n",
    "#         csv_lines = csv.reader(csv_file,delimiter=',')\n",
    "#         stopwords = list(csv_lines)\n",
    "#     return [word for word in joined.split() if word not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text_no_stopwords(text:str):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    eliminates stopwords only \n",
    "    \n",
    "    :param text - a string to work on\n",
    "    \n",
    "    :returns a cleaned text without punctuation\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    text_splitted_to_chars = [char for char in text if char not in string.punctuation]\n",
    "    joined = ''.join(text_splitted_to_chars)\n",
    "   \n",
    "    return joined.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def apply_regex_rules_on_naming_csv(self, replace_with_this_str: str, input_name: str, csv_path: str):\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        Adds to every name hebrew prefixes that might exists on the data.\n",
    "\n",
    "        This method is very expansive and not recommended when not necessary.\n",
    "\n",
    "        :param replace_with_this_str - the string to be replaced with\n",
    "\n",
    "        :param input_name - name string\n",
    "\n",
    "        :param csv_path - the csv that contains the names to be subtracted from each and every matched column\n",
    "\n",
    "\n",
    "        :returns the element after subtracting matched words\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # initalization\n",
    "        updated_name = input_name\n",
    "        names_list = list()\n",
    "        rgx_list = list()\n",
    "\n",
    "        # open the csv file with the words to eliminate\n",
    "        with open(csv_path, \"r\", encoding='utf-8') as csv_file:\n",
    "\n",
    "            names_list = csv.reader(csv_file, delimiter=',')\n",
    "\n",
    "            names = [row[0] for row in names_list]\n",
    "\n",
    "            # add selcted prefixes\n",
    "            for name in names:\n",
    "                rgx_list.append(str.format(\"ו?\" + name))\n",
    "                rgx_list.append(str.format(\"ל?\" + name))\n",
    "                rgx_list.append(str.format(\"כ?ש?\" + name))\n",
    "                rgx_list.append(str.format(\"ה?\" + name))\n",
    "                rgx_list.append(str.format(\"ב?\" + name))\n",
    "                rgx_list.append(str.format(\"מ?\" + name))\n",
    "                rgx_list.append(str.format(\"ש?\" + name))\n",
    "                rgx_list.append(str.format(\"כ?\" + name))\n",
    "                rgx_list.append(name)\n",
    "\n",
    "                if len(name.split()) > 1:\n",
    "                    rgx_list.append(str.format(name.split()[0] + '-' + name.split()[1]))\n",
    "\n",
    "                if len(name.split('-')) > 1:\n",
    "                    rgx_list.append(str.format(name.split('-')[0] + ' ' + name.split('-')[1]))\n",
    "\n",
    "            for rgx_match in rgx_list:\n",
    "                # take only specific words - not substrings, \\\\b is the word border.\n",
    "                pattern = re.compile(str.format(\"\\\\b{0}\\\\b\", rgx_match))\n",
    "                updated_name = re.sub(pattern, replace_with_this_str, input_name)\n",
    "\n",
    "        after_elimination = ' '.join(updated_name.split())\n",
    "\n",
    "        return after_elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clean_text(text):\n",
    "#     text_splitted_to_chars = [char for char in text if char not in string.punctuation]\n",
    "#     joined = ''.join(text_splitted_to_chars)\n",
    "    \n",
    "#     text_splitted_to_chars = [char for char in text_splitted_to_chars if char not in string.digits]\n",
    "#     joined = ''.join(text_splitted_to_chars)\n",
    "\n",
    "#     after_stopwords = apply_regex_rules_on_naming_csv('',joined,'C:/Users/Itai Ofir/HebrewCourtVerdictsAnalyzer/ML/extensive_stopwords_after_filter.csv')\n",
    "        \n",
    "#     return after_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text:str, stopwords_path:str, naming_path:str):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    cleans given text\n",
    "    \n",
    "    eliminates all matched occurences found on the naming and stopwords files from the given string\n",
    "    \n",
    "    applies hebrew prefixes when searching\n",
    "    \n",
    "    :param text - the given text string\n",
    "    \n",
    "    :param stopwords_path - the path of the stopwords file\n",
    "    \n",
    "    :param naming_path - the path of the common namings file\n",
    "    \n",
    "    :returns the text after elimination\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    text_splitted_to_chars = [char for char in text if char not in string.punctuation]\n",
    "    joined = ''.join(text_splitted_to_chars)\n",
    "    \n",
    "    text_splitted_to_chars = [char for char in text_splitted_to_chars if char not in string.digits]\n",
    "    joined = ''.join(text_splitted_to_chars)\n",
    "    \n",
    "    after_stopwords = apply_regex_rules_on_naming_csv('',joined,stopwords_path)\n",
    "    after_naming = apply_regex_rules_on_naming_csv('',after_stopwords,naming_path)\n",
    "    \n",
    "    return after_naming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#after = clean_text(\"איתי הלך לטיול , הוא גם עו'ד גם עוד וגם שופט למרות',- שה352וא חזק\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_best_n_gram_for_each_category(input_path,categories,n_grams,dest_path):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    checks the best ngram for every category\n",
    "    \n",
    "    tries all of values stored on 'n_grams' dict\n",
    "    \n",
    "    after the precedure dumps the results text to file on the dest_apth\n",
    "    \n",
    "    :param input_path - a string of the path where the ready to clasiify verdict are present and ordered.\n",
    "    \n",
    "    :param cateogires - a list of strings that represents the category names\n",
    "    \n",
    "    :param n_grams - a list of round numbers that will be applied as test input for the vectorizer\n",
    "    \n",
    "    :param dest_path - a string of the destination path - on that path the results will be written\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    for cat in categories:\n",
    "        path=dest_path+'/'+cat+'.txt'\n",
    "        with open(path,'w',encoding='utf-8') as file:\n",
    "            for n_gram_val in n_grams:\n",
    "                train,test,y_train,y_test = create_train_test_of_specified_verdict_category(cat,input_path)\n",
    "                model_series = []\n",
    "                vec = TfidfVectorizer(ngram_range = (n_gram_val,n_gram_val))\n",
    "                transformed = vec.fit_transform(train[\"Verdict_Text\"])\n",
    "                model = MultinomialNB().fit(transformed,y_train.to_numpy(dtype=float).ravel())\n",
    "                test_transformed = vec.transform(test[\"Verdict_Text\"])\n",
    "                y_test_predict = model.predict(test_transformed)\n",
    "                file.write(str.format('\\nn_gram val : {0} \\n{1}\\n',n_gram_val,classification_report(y_test.to_numpy(dtype=float).ravel(),y_test_predict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_dump_model_and_tfidf_vectorizer(category:str, input_path:str, model_destination_path:str,tfidf_destination_path:str ,desired_n_gram, test_size):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    trains a specific category model and with a specific n-gram and dump it to the destination\n",
    "    \n",
    "    :param category - a string that holds the current category\n",
    "    \n",
    "    :param input_path - a string that holds the root folder of the categories-ordered data\n",
    "    \n",
    "    :param destination_path - a string that holds the path of the dumped model\n",
    "    \n",
    "    :param desired_n_gram - a number with the optimal n_gram for that category\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    train,test,y_train,y_test = create_train_test_of_specified_verdict_category(category,input_path,test_size)\n",
    "    vec = TfidfVectorizer(ngram_range = (desired_n_gram,desired_n_gram))\n",
    "    transformed = vec.fit_transform(train[\"Verdict_Text\"])\n",
    "    model = MultinomialNB().fit(transformed,y_train.to_numpy(dtype=float).ravel())\n",
    "    \n",
    "    with open(model_destination_path,'wb') as model_file:\n",
    "        pickle.dump(model,model_file)\n",
    "        \n",
    "    with open(tfidf_destination_path,'wb') as tfidf_file:\n",
    "        pickle.dump(vec,tfidf_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def automate_train_based_on_specific_ngram(categories, input_path:str, destination_path:str):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    uses the ngram check that has been done for each category and applies the best ngram for each category\n",
    "    \n",
    "    then dumps the model to the destination folder\n",
    "    \n",
    "    :param categoires - a list of strings that holds the categories\n",
    "    \n",
    "    :param input_path - a string of the root readytoclassify folder\n",
    "    \n",
    "    :param destination_path - a string of the destination folder\n",
    "    \n",
    "    \"\"\"\n",
    "    count = 1\n",
    "    try:\n",
    "        \n",
    "        for category in categories:\n",
    "            \n",
    "            print(str(count)+' / '+ str(len(categories)))\n",
    "            \n",
    "            if category == 'Administrative':\n",
    "                train_and_dump_model_and_tfidf_vectorizer(category, input_path, destination_path+'/'+category+'.pkl',destination_path+'/'+category+'.tfidf', 9, 0.3)\n",
    "            \n",
    "            elif category == 'Civil':\n",
    "                train_and_dump_model_and_tfidf_vectorizer(category, input_path, destination_path+'/'+category+'.pkl',destination_path+'/'+category+'.tfidf', 9, 0.3)\n",
    "            \n",
    "            elif category == 'Constitutional':\n",
    "                train_and_dump_model_and_tfidf_vectorizer(category, input_path, destination_path+'/'+category+'.pkl',destination_path+'/'+category+'.tfidf', 4, 0.3)\n",
    "            \n",
    "            elif category == 'Criminal':\n",
    "                train_and_dump_model_and_tfidf_vectorizer(category, input_path, destination_path+'/'+category+'.pkl',destination_path+'/'+category+'.tfidf', 6, 0.3)\n",
    "    \n",
    "            elif category == 'Family':\n",
    "                train_and_dump_model_and_tfidf_vectorizer(category, input_path, destination_path+'/'+category+'.pkl',destination_path+'/'+category+'.tfidf', 8, 0.3)\n",
    "                    \n",
    "            elif category == 'International law':\n",
    "                train_and_dump_model_and_tfidf_vectorizer(category, input_path, destination_path+'/'+category+'.pkl',destination_path+'/'+category+'.tfidf', 9, 0.3)       \n",
    "                  \n",
    "            elif category == 'Labor and Employment':\n",
    "                train_and_dump_model_and_tfidf_vectorizer(category, input_path, destination_path+'/'+category+'.pkl',destination_path+'/'+category+'.tfidf', 7, 0.3)\n",
    "                    \n",
    "            elif category == 'National security, military, and the territories':\n",
    "                train_and_dump_model_and_tfidf_vectorizer(category, input_path, destination_path+'/'+category+'.pkl',destination_path+'/'+category+'.tfidf', 2, 0.3)\n",
    "                    \n",
    "            elif category == 'Religious':\n",
    "                train_and_dump_model_and_tfidf_vectorizer(category, input_path, destination_path+'/'+category+'.pkl',destination_path+'/'+category+'.tfidf', 8, 0.3)      \n",
    "                  \n",
    "            elif category == 'Social security, Health Insurance, Pension':\n",
    "                train_and_dump_model_and_tfidf_vectorizer(category, input_path, destination_path+'/'+category+'.pkl',destination_path+'/'+category+'.tfidf', 7, 0.3)\n",
    "            \n",
    "            count += 1\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# input_path = 'C:/Users/Itai/HebrewCourtVerdictsAnalyzer/ML/data/readytoclassify'\n",
    "# categories = ['Family','Labor and Employment','Constitutional','Administrative','Civil','Criminal','International law','National security, military, and the territories','Religious','Social security, Health Insurance, Pension']\n",
    "# n_gram = [1,2,3,4,5,6,7,8,9,10]\n",
    "# dest_path = 'C:/Users/Itai/HebrewCourtVerdictsAnalyzer/ML/data'\n",
    "# check_best_n_gram_for_each_category(input_path,categories,n_gram,dest_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 10\n",
      "2 / 10\n"
     ]
    }
   ],
   "source": [
    "input_path = 'C:/Users/Itai/HebrewCourtVerdictsAnalyzer/ML/data/readytoclassify'\n",
    "categories = ['Family','Labor and Employment','Constitutional','Administrative','Civil','Criminal','International law','National security, military, and the territories','Religious','Social security, Health Insurance, Pension']\n",
    "dest_path = 'C:/Users/Itai/HebrewCourtVerdictsAnalyzer/ML/data/models'\n",
    "automate_train_based_on_specific_ngram(categories,input_path,dest_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_classifiers(input_path:str):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    loads the classifier from the given path and returns a dictionary with the category name as key\n",
    "    and the model itself as the value\n",
    "    \n",
    "    :param input_path - a string the represnets the models folder\n",
    "    \n",
    "    :returns string-model and string-tfidf dictionary\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    models_dict = dict()\n",
    "    tfidf_dict = dict()\n",
    "    \n",
    "    for file in os.scandir(input_path):\n",
    "        \n",
    "        if os.path.isfile(file):\n",
    "            \n",
    "            if os.path.basename(file).find('.pkl'):\n",
    "                \n",
    "                current_category = os.path.basename(file).split('.pkl')[0]\n",
    "                \n",
    "                with open(file,'rb') as pickle_file:\n",
    "                    cur_model = pickle.load(pickle_file)\n",
    "                    models_dict[current_category] = cur_model\n",
    "                \n",
    "                 with open(file,'rb') as tfidf_file:\n",
    "                    cur_tfidf = pickle.load(tfidf_file)\n",
    "                    tfidf_dict[current_category] = cur_tfidf\n",
    "    \n",
    "    return models_dict,tfidf_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "models,tfidfs = load_classifiers('C:/Users/Itai/HebrewCourtVerdictsAnalyzer/ML/data/models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Administrative': MultinomialNB(),\n",
       " 'Civil': MultinomialNB(),\n",
       " 'Constitutional': MultinomialNB(),\n",
       " 'Criminal': MultinomialNB(),\n",
       " 'Family': MultinomialNB(),\n",
       " 'International law': MultinomialNB(),\n",
       " 'Labor and Employment': MultinomialNB(),\n",
       " 'National security, military, and the territories': MultinomialNB(),\n",
       " 'Religious': MultinomialNB(),\n",
       " 'Social security, Health Insurance, Pension': MultinomialNB()}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_to_ngram = {'Administrative':9,\n",
    "                          'Civil':9,\n",
    "                          'Constitutional':4,\n",
    "                          'Criminal':6,\n",
    "                          'Family':8,\n",
    "                          'International law':9,\n",
    "                          'Labor and Employment':7,\n",
    "                          'National security, military, and the territories':2,\n",
    "                          'Religious':8,\n",
    "                          'Social security, Health Insurance, Pension':7\n",
    "                         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(verdict_summary:str, models:dict, category_to_ngram:dict):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    passing the input verdict string as the prediction input for all of the pre-trained models\n",
    "    \n",
    "    the highest probability will be the verdict category\n",
    "    \n",
    "    :param verdict_summary - a string of the verdict summary\n",
    "    \n",
    "    :param models - category to model dictionary\n",
    "    \n",
    "    :param - category_to_nagram - category to ngram dictionary\n",
    "    \n",
    "    :returns - the chosen category string\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    category_to_score = dict()\n",
    "    score_to_category = dict()\n",
    "    \n",
    "    for category,model in zip(models.keys(),models.values()):\n",
    "        cur_ngram = category_to_ngram[category]\n",
    "        cur_vectorizer = TfidfVectorizer(ngram_range = (cur_ngram,cur_ngram))\n",
    "        tranformed = cur_vectorizer.transform(verdict_summary)\n",
    "        cur_prob = model.predict_proba(transformed)\n",
    "        category_to_score[category] = cur_prob\n",
    "        score_to_category[cur_prob] = category\n",
    "    \n",
    "    max_prob = max(category_to_score.values())\n",
    "    \n",
    "    return score_to_category[max_prob]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "The TF-IDF vectorizer is not fitted",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-f840f031cac8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"השופט א' א' לוי:\\nבכתב-אישום שהוגש לבית המשפט המחוזי בחיפה, יוחסו למערער ולדמיר ואן אוסט (להלן: דמיר) עבירות על פי פקודת הסמים המסוכנים. נטען, כי במהלך שנת 2008 קיבל דמיר, על פי בקשתו, מאחיו שבהולנד זרעי קנבוס, ובדירה ששכר החל לגדל צמחי קנבוס מתוך כוונה להפיק מהם סם בכמויות מסחריות. בתאריך 15.3.09 קטף דמיר צמחי קנבוס במשקל כולל של 87.4 ק\\\"ג נטו, ועל פי תיאום מוקדם עם המערער הם הוציאו את הצמחים משקיות הואקום לצורך יבושם. בגין עובדות אלו בהן הודה המערער, הרשיעו בית המשפט המחוזי בעבירה של החזקת סם מסוכן שלא לצריכה עצמית, ובהמשך דן אותו ל-12 חודשי מאסר, שתי תקופות של מאסר על-תנאי, קנס בסך 20,000 ש\\\"ח, והוא נפסל מהחזיק או מקבל רישיון נהיגה במשך 9 חודשים. להשלמת התמונה נוסיף, כי דמיר נדון ל-27 חודשי מאסר, שתי תקופות של מאסר על-תנאי, קנס בסך 60.000 ש\\\"ח והוא נפסל מנהיגה במשך 18 חודשים.\\nבערעור שבפנינו מלין המערער על חומרת העונש. נטען כי בית המשפט המחוזי נתפס לשגגה שעה שהניח כי למערער עבר פלילי; עוד נטען כי חלקו של המערער בפרשה שולי; נכון היה לאמץ את המלצת שרות המבחן ולהימנע מכליאתו; מאז שוחרר ממעצרו הוא עלה על דרך המלך; הפסיקה אליה הפנתה ערכאה קמא דנה במקרים חמורים מאלה עליהם נקרא המערער לתת את הדין.\\nהמערער יתייצב לשאת במאסרו בתאריך ה' באלול התש\\\"ע (15.8.10) במזכירות בית המשפט המחוזי בחיפה, עד השעה 10:00.\\nניתן היום, ט\\\"ז באב התש\\\"ע ( 27.07.2010).\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcategory_to_ngram\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-63-bd0fc665fd00>\u001b[0m in \u001b[0;36mclassify\u001b[1;34m(verdict_summary, models, category_to_ngram)\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mcur_ngram\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcategory_to_ngram\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcategory\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mcur_vectorizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mngram_range\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcur_ngram\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcur_ngram\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0mtranformed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcur_vectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mverdict_summary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[0mcur_prob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mcategory_to_score\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcategory\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcur_prob\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, raw_documents)\u001b[0m\n\u001b[0;32m   1870\u001b[0m             \u001b[0mTf\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0midf\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mweighted\u001b[0m \u001b[0mdocument\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mterm\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1871\u001b[0m         \"\"\"\n\u001b[1;32m-> 1872\u001b[1;33m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'The TF-IDF vectorizer is not fitted'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1873\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1874\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m   1039\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1040\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1041\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'name'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1042\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFittedError\u001b[0m: The TF-IDF vectorizer is not fitted"
     ]
    }
   ],
   "source": [
    "res = classify(\"השופט א' א' לוי:\\nבכתב-אישום שהוגש לבית המשפט המחוזי בחיפה, יוחסו למערער ולדמיר ואן אוסט (להלן: דמיר) עבירות על פי פקודת הסמים המסוכנים. נטען, כי במהלך שנת 2008 קיבל דמיר, על פי בקשתו, מאחיו שבהולנד זרעי קנבוס, ובדירה ששכר החל לגדל צמחי קנבוס מתוך כוונה להפיק מהם סם בכמויות מסחריות. בתאריך 15.3.09 קטף דמיר צמחי קנבוס במשקל כולל של 87.4 ק\\\"ג נטו, ועל פי תיאום מוקדם עם המערער הם הוציאו את הצמחים משקיות הואקום לצורך יבושם. בגין עובדות אלו בהן הודה המערער, הרשיעו בית המשפט המחוזי בעבירה של החזקת סם מסוכן שלא לצריכה עצמית, ובהמשך דן אותו ל-12 חודשי מאסר, שתי תקופות של מאסר על-תנאי, קנס בסך 20,000 ש\\\"ח, והוא נפסל מהחזיק או מקבל רישיון נהיגה במשך 9 חודשים. להשלמת התמונה נוסיף, כי דמיר נדון ל-27 חודשי מאסר, שתי תקופות של מאסר על-תנאי, קנס בסך 60.000 ש\\\"ח והוא נפסל מנהיגה במשך 18 חודשים.\\nבערעור שבפנינו מלין המערער על חומרת העונש. נטען כי בית המשפט המחוזי נתפס לשגגה שעה שהניח כי למערער עבר פלילי; עוד נטען כי חלקו של המערער בפרשה שולי; נכון היה לאמץ את המלצת שרות המבחן ולהימנע מכליאתו; מאז שוחרר ממעצרו הוא עלה על דרך המלך; הפסיקה אליה הפנתה ערכאה קמא דנה במקרים חמורים מאלה עליהם נקרא המערער לתת את הדין.\\nהמערער יתייצב לשאת במאסרו בתאריך ה' באלול התש\\\"ע (15.8.10) במזכירות בית המשפט המחוזי בחיפה, עד השעה 10:00.\\nניתן היום, ט\\\"ז באב התש\\\"ע ( 27.07.2010).\",models,category_to_ngram)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
